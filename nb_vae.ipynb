{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# tfe = tf.contrib.eager\n",
    "#tf.enable_eager_execution()\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "#import PIL\n",
    "import imageio\n",
    "from IPython import display\n",
    "import pathlib\n",
    "AUTOTUNE=tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir=pathlib.Path.cwd()/'../Documents/img_align_celeba/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_image_paths=list(dir.glob('*'))\n",
    "all_image_paths = [str(path) for path in all_image_paths]\n",
    "image_count = len(all_image_paths)\n",
    "image_count\n",
    "\n",
    "#train_paths=all_image_paths[:-20000]\n",
    "train_paths=all_image_paths[:6400]\n",
    "test_paths=all_image_paths[-320:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_image_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "  image = tf.image.decode_jpeg(image, channels=3)\n",
    "  image = tf.image.resize(image, [192, 192])\n",
    "  image /= 255.0  # normalize to [0,1] range\n",
    "  #image = tf.image.convert_image_dtype(image, tf.float16)\n",
    "\n",
    "  return image\n",
    "\n",
    "def load_and_preprocess_image(path):\n",
    "  image = tf.io.read_file(path)\n",
    "  return preprocess_image(image)\n",
    "\n",
    "\n",
    "def from_path_to_tensor(paths, batch_size):\n",
    "    path_ds=tf.data.Dataset.from_tensor_slices(paths)\n",
    "    ds=path_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
    "    ds=ds.batch(batch_size)\n",
    "    ds=ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE=image_count//9\n",
    "\n",
    "train_set= from_path_to_tensor(train_paths, BATCH_SIZE)\n",
    "\n",
    "\n",
    "\n",
    "test_set=from_path_to_tensor(test_paths, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(tf.keras.Model):\n",
    "  def __init__(self, latent_dim):\n",
    "    super(CVAE, self).__init__()\n",
    "    self.latent_dim = latent_dim\n",
    "    self.inference_net = tf.keras.Sequential(\n",
    "      [\n",
    "          tf.keras.layers.InputLayer(input_shape=(192, 192, 3)),\n",
    "          tf.keras.layers.Conv2D(\n",
    "              filters=8, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "          tf.keras.layers.Conv2D(\n",
    "              filters=4, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "          tf.keras.layers.Conv2D(\n",
    "              filters=2, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "          tf.keras.layers.Flatten(),\n",
    "          # No activation\n",
    "          tf.keras.layers.Dense(latent_dim + latent_dim),\n",
    "      ]\n",
    "    )\n",
    "\n",
    "    self.generative_net = tf.keras.Sequential(\n",
    "        [\n",
    "          tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
    "          tf.keras.layers.Dense(units=24*24*32, activation=tf.nn.relu),\n",
    "          tf.keras.layers.Reshape(target_shape=(24, 24, 32)),\n",
    "          tf.keras.layers.Conv2DTranspose(\n",
    "              filters=2,\n",
    "              kernel_size=3,\n",
    "              strides=(2, 2),\n",
    "              padding=\"SAME\",\n",
    "              activation='relu'),\n",
    "          tf.keras.layers.Conv2DTranspose(\n",
    "              filters=4,\n",
    "              kernel_size=3,\n",
    "              strides=(2, 2),\n",
    "              padding=\"SAME\",\n",
    "              activation='relu'),\n",
    "          tf.keras.layers.Conv2DTranspose(\n",
    "              filters=8,\n",
    "              kernel_size=3,\n",
    "              strides=(2, 2),\n",
    "              padding=\"SAME\",\n",
    "              activation='relu'),  \n",
    "          # No activation\n",
    "          tf.keras.layers.Conv2DTranspose(\n",
    "              filters=3, kernel_size=3, strides=(1, 1), padding=\"SAME\", activation='sigmoid'),\n",
    "        ]\n",
    "    )\n",
    "  \n",
    "  @tf.function\n",
    "  def sample(self, eps=None):\n",
    "    if eps is None:\n",
    "      eps = tf.random.normal(shape=(4, self.latent_dim))\n",
    "    return self.decode(eps)\n",
    "  @tf.function\n",
    "  def encode(self, x):\n",
    "    mean, logvar = tf.split(self.inference_net(x), num_or_size_splits=2, axis=1)\n",
    "    return mean, logvar\n",
    "  \n",
    "  @tf.function\n",
    "  def reparameterize(self, mean, logvar):\n",
    "    eps = tf.random.normal(shape=mean.shape)\n",
    "    return eps * tf.exp(logvar * .5) + mean\n",
    "  @tf.function\n",
    "  def decode(self, z):\n",
    "    return self.generative_net(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "  log2pi = tf.math.log(2. * np.pi)\n",
    "  return tf.reduce_sum(\n",
    "      -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
    "      axis=raxis)\n",
    "\n",
    "def compute_loss(model, x, test=False):\n",
    "    mean, logvar = model.encode(x)\n",
    "    z = model.reparameterize(mean, logvar)\n",
    "    x_r = model.decode(z)\n",
    "\n",
    "    rc_loss = K.sum(K.binary_crossentropy(\n",
    "    K.batch_flatten(x), \n",
    "    K.batch_flatten(x_r)), axis=-1)\n",
    "\n",
    "    # Regularization term (KL divergence)\n",
    "    kl_loss = -0.5 * K.sum(1 + logvar \\\n",
    "                             - K.square(mean) \\\n",
    "                             - K.exp(logvar), axis=-1)\n",
    "    \n",
    "    # Average over mini-batch\n",
    "    total_loss = K.mean(rc_loss + kl_loss)\n",
    "    \n",
    "    if test:\n",
    "        return rc_loss, kl_loss, total_loss, x, x_r\n",
    "    else:\n",
    "        return rc_loss, kl_loss, total_loss\n",
    "\n",
    "\n",
    "def compute_gradients(model, x):\n",
    "  with tf.GradientTape() as tape:\n",
    "    _, _2, loss = compute_loss(model, x)\n",
    "  return tape.gradient(loss, model.trainable_variables), loss\n",
    "\n",
    "def apply_gradients(optimizer, gradients, variables):\n",
    "     optimizer.apply_gradients(zip(gradients, variables))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "latent_dim = 50\n",
    "num_examples_to_generate = 4\n",
    "\n",
    "# keeping the random vector constant for generation (prediction) so\n",
    "# it will be easier to see the improvement.\n",
    "random_vector_for_generation = tf.random.normal(\n",
    "    shape=[num_examples_to_generate, latent_dim])\n",
    "model = CVAE(latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  predictions = model.sample(test_input)\n",
    "  fig = plt.figure(figsize=(2,2))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "      plt.subplot(2, 2, i+1)\n",
    "      plt.imshow(predictions[i, :, :, :])\n",
    "      plt.axis('off')\n",
    "\n",
    "  # tight_layout minimizes the overlap between 2 sub-plots\n",
    "  #plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(metrics, tags, test=False):\n",
    "    if test:\n",
    "        with test_summary_writer.as_default():\n",
    "            for metric, tag in zip(metrics, tags):\n",
    "                tf.summary.scalar(tag, metric.result(), step=optimizer.iterations)\n",
    "                metric.reset_states()\n",
    "    else:\n",
    "        with train_summary_writer.as_default():\n",
    "            for metric, tag in zip(metrics, tags):\n",
    "                tf.summary.scalar(tag, metric.result(), step=optimizer.iterations)\n",
    "                metric.reset_states()\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(batch, model, optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        rc_loss, kl_loss, loss = compute_loss(model, batch)\n",
    "    gradients=tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return rc_loss, kl_loss, loss\n",
    "\n",
    "\n",
    "losses=['loss','rc_loss','kl_loss']\n",
    "\n",
    "def train_vae(model, optimizer, epochs, dataset, print_interval, save_interval, log_freq=10):\n",
    "    #summary_writer = tf.summary.create_file_writer(DIR)\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        avg_loss=tf.metrics.Mean(name='loss', dtype=tf.float32)\n",
    "        avg_val=tf.metrics.Mean(name='val_loss', dtype=tf.float32)\n",
    "        avg_train_rc=tf.metrics.Mean(name='training_rc_loss', dtype=tf.float32)\n",
    "        avg_val_rc=tf.metrics.Mean(name='val_rc_loss', dtype=tf.float32)\n",
    "        avg_train_kl=tf.metrics.Mean(name='training_kl_loss', dtype=tf.float32)\n",
    "        avg_val_kl=tf.metrics.Mean(name='val_kl_loss', dtype=tf.float32)\n",
    "        start_time = time.time()\n",
    "        for step, batch in enumerate(dataset):\n",
    "            rc_loss_x, kl_loss_x, loss_x = train_step(batch, model, optimizer)\n",
    "            avg_loss.update_state(loss_x)\n",
    "            avg_train_rc.update_state(rc_loss_x)\n",
    "            avg_train_kl.update_state(kl_loss_x)\n",
    "            if tf.equal(optimizer.iterations % log_freq, 0):\n",
    "                print('log', '{}'.format(optimizer.iterations.numpy()))\n",
    "                summarize([avg_loss, avg_train_rc, avg_train_kl], losses)\n",
    "            if (time.time()-start_time)>5:\n",
    "                print('time to check!')\n",
    "                for batch in test_set:\n",
    "                    print('do we get here?')\n",
    "                    rc_val, kl_val, val, x, x_r=compute_loss(model, batch, test=True)\n",
    "                    avg_val.update_state(val)\n",
    "                    avg_val_rc.update_state(rc_val)\n",
    "                    avg_val_kl.update_state(kl_val)\n",
    "                print('Batch',step,'done.', 'loss on validaiton set: {}'.format(avg_val.result()))\n",
    "                summarize([avg_val,avg_val_rc, avg_val_kl], losses,test=True)\n",
    "                with test_summary_writer.as_default():\n",
    "                    tf.summary.image('input', x, step = optimizer.iterations, max_outputs=3)\n",
    "                    tf.summary.image('output', x_r, step = optimizer.iterations, max_outputs=3)\n",
    "                start_time=time.time()\n",
    "            if step+1 % save_interval ==0:\n",
    "                generate_and_save_images(model, epoch, step+1, random_vector_for_generation)\n",
    "                model.weight_saver(TRAINING_DIR, epoch, i)\n",
    "                end_time = time.time()\n",
    "    #generate_and_save_images(model, epoch,0, random_vector_for_generation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=tf.optimizers.Adadelta(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DIR='train1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_summary_writer = tf.summary.create_file_writer(TRAINING_DIR+'/summaries/train')\n",
    "test_summary_writer = tf.summary.create_file_writer(TRAINING_DIR+'/summaries/test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vae(model, optimizer, 1, train_set, 10, 500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

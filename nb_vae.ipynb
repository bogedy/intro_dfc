{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# tfe = tf.contrib.eager\n",
    "#tf.enable_eager_execution()\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "#import PIL\n",
    "import imageio\n",
    "from IPython import display\n",
    "import pathlib\n",
    "AUTOTUNE=tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-beta0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir=pathlib.Path.cwd()/'../Documents/img_align_celeba/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_image_paths=list(dir.glob('*'))\n",
    "all_image_paths = [str(path) for path in all_image_paths]\n",
    "image_count = len(all_image_paths)\n",
    "image_count\n",
    "\n",
    "#train_paths=all_image_paths[:-20000]\n",
    "train_paths=all_image_paths[:6400]\n",
    "test_paths=all_image_paths[-320:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/isaiahk/intro_dfc/../Documents/img_align_celeba/008239.jpg'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_image_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "  image = tf.image.decode_jpeg(image, channels=3)\n",
    "  image = tf.image.resize(image, [192, 192])\n",
    "  image /= 255.0  # normalize to [0,1] range\n",
    "  #image = tf.image.convert_image_dtype(image, tf.float16)\n",
    "\n",
    "  return image\n",
    "\n",
    "def load_and_preprocess_image(path):\n",
    "  image = tf.io.read_file(path)\n",
    "  return preprocess_image(image)\n",
    "\n",
    "\n",
    "def from_path_to_tensor(paths, batch_size):\n",
    "    path_ds=tf.data.Dataset.from_tensor_slices(paths)\n",
    "    ds=path_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
    "    ds=ds.batch(batch_size)\n",
    "    ds=ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE=image_count//9\n",
    "\n",
    "train_set= from_path_to_tensor(train_paths, BATCH_SIZE)\n",
    "\n",
    "\n",
    "\n",
    "test_set=from_path_to_tensor(test_paths, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(tf.keras.Model):\n",
    "  def __init__(self, latent_dim):\n",
    "    super(CVAE, self).__init__()\n",
    "    self.latent_dim = latent_dim\n",
    "    self.inference_net = tf.keras.Sequential(\n",
    "      [\n",
    "          tf.keras.layers.InputLayer(input_shape=(192, 192, 3)),\n",
    "          tf.keras.layers.Conv2D(\n",
    "              filters=8, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "          tf.keras.layers.Conv2D(\n",
    "              filters=4, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "          tf.keras.layers.Conv2D(\n",
    "              filters=2, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "          tf.keras.layers.Flatten(),\n",
    "          # No activation\n",
    "          tf.keras.layers.Dense(latent_dim + latent_dim),\n",
    "      ]\n",
    "    )\n",
    "\n",
    "    self.generative_net = tf.keras.Sequential(\n",
    "        [\n",
    "          tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
    "          tf.keras.layers.Dense(units=24*24*32, activation=tf.nn.relu),\n",
    "          tf.keras.layers.Reshape(target_shape=(24, 24, 32)),\n",
    "          tf.keras.layers.Conv2DTranspose(\n",
    "              filters=2,\n",
    "              kernel_size=3,\n",
    "              strides=(2, 2),\n",
    "              padding=\"SAME\",\n",
    "              activation='relu'),\n",
    "          tf.keras.layers.Conv2DTranspose(\n",
    "              filters=4,\n",
    "              kernel_size=3,\n",
    "              strides=(2, 2),\n",
    "              padding=\"SAME\",\n",
    "              activation='relu'),\n",
    "          tf.keras.layers.Conv2DTranspose(\n",
    "              filters=8,\n",
    "              kernel_size=3,\n",
    "              strides=(2, 2),\n",
    "              padding=\"SAME\",\n",
    "              activation='relu'),  \n",
    "          # No activation\n",
    "          tf.keras.layers.Conv2DTranspose(\n",
    "              filters=3, kernel_size=3, strides=(1, 1), padding=\"SAME\", activation='sigmoid'),\n",
    "        ]\n",
    "    )\n",
    "  \n",
    "  @tf.function\n",
    "  def sample(self, eps=None):\n",
    "    if eps is None:\n",
    "      eps = tf.random.normal(shape=(4, self.latent_dim))\n",
    "    return self.decode(eps)\n",
    "  @tf.function\n",
    "  def encode(self, x):\n",
    "    mean, logvar = tf.split(self.inference_net(x), num_or_size_splits=2, axis=1)\n",
    "    return mean, logvar\n",
    "  \n",
    "  @tf.function\n",
    "  def reparameterize(self, mean, logvar):\n",
    "    eps = tf.random.normal(shape=mean.shape)\n",
    "    return eps * tf.exp(logvar * .5) + mean\n",
    "  @tf.function\n",
    "  def decode(self, z):\n",
    "    return self.generative_net(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "  log2pi = tf.math.log(2. * np.pi)\n",
    "  return tf.reduce_sum(\n",
    "      -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
    "      axis=raxis)\n",
    "\n",
    "def compute_loss(model, x, test=False):\n",
    "    mean, logvar = model.encode(x)\n",
    "    z = model.reparameterize(mean, logvar)\n",
    "    x_r = model.decode(z)\n",
    "\n",
    "    rc_loss = K.sum(K.binary_crossentropy(\n",
    "    K.batch_flatten(x), \n",
    "    K.batch_flatten(x_r)), axis=-1)\n",
    "\n",
    "    # Regularization term (KL divergence)\n",
    "    kl_loss = -0.5 * K.sum(1 + logvar \\\n",
    "                             - K.square(mean) \\\n",
    "                             - K.exp(logvar), axis=-1)\n",
    "    \n",
    "    # Average over mini-batch\n",
    "    total_loss = K.mean(rc_loss + kl_loss)\n",
    "    \n",
    "    if test:\n",
    "        return rc_loss, kl_loss, total_loss, x, x_r\n",
    "    else:\n",
    "        return rc_loss, kl_loss, total_loss\n",
    "\n",
    "\n",
    "def compute_gradients(model, x):\n",
    "  with tf.GradientTape() as tape:\n",
    "    _, _2, loss = compute_loss(model, x)\n",
    "  return tape.gradient(loss, model.trainable_variables), loss\n",
    "\n",
    "def apply_gradients(optimizer, gradients, variables):\n",
    "     optimizer.apply_gradients(zip(gradients, variables))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "latent_dim = 50\n",
    "num_examples_to_generate = 4\n",
    "\n",
    "# keeping the random vector constant for generation (prediction) so\n",
    "# it will be easier to see the improvement.\n",
    "random_vector_for_generation = tf.random.normal(\n",
    "    shape=[num_examples_to_generate, latent_dim])\n",
    "model = CVAE(latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 95, 95, 8)         224       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 47, 47, 4)         292       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 23, 23, 2)         74        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1058)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               105900    \n",
      "=================================================================\n",
      "Total params: 106,490\n",
      "Trainable params: 106,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.inference_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  predictions = model.sample(test_input)\n",
    "  fig = plt.figure(figsize=(2,2))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "      plt.subplot(2, 2, i+1)\n",
    "      plt.imshow(predictions[i, :, :, :])\n",
    "      plt.axis('off')\n",
    "\n",
    "  # tight_layout minimizes the overlap between 2 sub-plots\n",
    "  #plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()\n",
    "\n",
    "mse=tf.losses.MeanSquaredError()\n",
    "\n",
    "@tf.function\n",
    "def p_loss(model, x):\n",
    "    mean, logvar = model.encode(x)\n",
    "    z = model.reparameterize(mean, logvar)\n",
    "    x_r = model.decode(z)\n",
    "    \n",
    "    outputs = [model.inference_net.get_layer(l).output for l in [\"conv2d\", \"conv2d_1\", \"conv2d_2\"]]\n",
    "    p_model = tf.keras.Model(outputs)\n",
    "    h1_list = model(x)\n",
    "    h2_list = model(x_r)\n",
    "    \n",
    "    rc_loss = 0.0\n",
    "    \n",
    "    for h1, h2, weight in zip(h1_list, h2_list):\n",
    "        rc_loss += mse(h1,h2)\n",
    "        \n",
    "    return rc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(metrics, tags, test=False):\n",
    "    if test:\n",
    "        with test_summary_writer.as_default():\n",
    "            for metric, tag in zip(metrics, tags):\n",
    "                tf.summary.scalar(tag, metric.result(), step=optimizer.iterations)\n",
    "                metric.reset_states()\n",
    "    else:\n",
    "        with train_summary_writer.as_default():\n",
    "            for metric, tag in zip(metrics, tags):\n",
    "                tf.summary.scalar(tag, metric.result(), step=optimizer.iterations)\n",
    "                metric.reset_states()\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(batch, model, optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        rc_loss, kl_loss, loss = compute_loss(model, batch)\n",
    "    gradients=tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return rc_loss, kl_loss, loss\n",
    "\n",
    "\n",
    "losses=['loss','rc_loss','kl_loss']\n",
    "\n",
    "def train_vae(model, optimizer, epochs, dataset, print_interval, save_interval, log_freq=10):\n",
    "    #summary_writer = tf.summary.create_file_writer(DIR)\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        avg_loss=tf.metrics.Mean(name='loss', dtype=tf.float32)\n",
    "        avg_val=tf.metrics.Mean(name='val_loss', dtype=tf.float32)\n",
    "        avg_train_rc=tf.metrics.Mean(name='training_rc_loss', dtype=tf.float32)\n",
    "        avg_val_rc=tf.metrics.Mean(name='val_rc_loss', dtype=tf.float32)\n",
    "        avg_train_kl=tf.metrics.Mean(name='training_kl_loss', dtype=tf.float32)\n",
    "        avg_val_kl=tf.metrics.Mean(name='val_kl_loss', dtype=tf.float32)\n",
    "        avg_p_loss=tf.metrics.Mean(name='p_loss',dtype=tf.float32)\n",
    "        start_time = time.time()\n",
    "        for step, batch in enumerate(dataset):\n",
    "            rc_loss_x, kl_loss_x, loss_x = train_step(batch, model, optimizer)\n",
    "            avg_loss.update_state(loss_x)\n",
    "            avg_train_rc.update_state(rc_loss_x)\n",
    "            avg_train_kl.update_state(kl_loss_x)\n",
    "            if tf.equal(optimizer.iterations % log_freq, 0):\n",
    "                print('log', '{}'.format(optimizer.iterations.numpy()))\n",
    "                summarize([avg_loss, avg_train_rc, avg_train_kl], losses)\n",
    "            if (time.time()-start_time)>5:\n",
    "                print('time to check!')\n",
    "                for batch in test_set:\n",
    "                    print('do we get here?')\n",
    "                    rc_val, kl_val, val, x, x_r=compute_loss(model, batch, test=True)\n",
    "                    ploss=p_loss(model, batch)\n",
    "                    avg_val.update_state(val)\n",
    "                    avg_val_rc.update_state(rc_val)\n",
    "                    avg_val_kl.update_state(kl_val)\n",
    "                    avg_p_loss.update_state(ploss)\n",
    "                print('Batch',step,'done.', 'loss on validaiton set: {}'.format(avg_val.result()))\n",
    "                summarize([avg_val,avg_val_rc, avg_val_kl], losses,test=True)\n",
    "                with test_summary_writer.as_default():\n",
    "                    tf.summary.image('input', x, step = optimizer.iterations, max_outputs=3)\n",
    "                    tf.summary.image('output', x_r, step = optimizer.iterations, max_outputs=3)\n",
    "                    tf.summary.scalar('p_loss', avg_p_loss.result(), step=optimizer.iterations)\n",
    "                    avg_p_loss.reset_states()\n",
    "                start_time=time.time()\n",
    "            if step+1 % save_interval ==0:\n",
    "                generate_and_save_images(model, epoch, step+1, random_vector_for_generation)\n",
    "                model.weight_saver(TRAINING_DIR, epoch, i)\n",
    "                end_time = time.time()\n",
    "    #generate_and_save_images(model, epoch,0, random_vector_for_generation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=tf.optimizers.Adadelta(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DIR='experiment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_summary_writer = tf.summary.create_file_writer(TRAINING_DIR+'/summaries/train')\n",
    "test_summary_writer = tf.summary.create_file_writer(TRAINING_DIR+'/summaries/test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0620 18:39:44.097499 140534846768896 deprecation.py:323] From /home/isaiahk/miniconda3/envs/tf2b/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1220: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log 10\n",
      "log 20\n",
      "log 30\n",
      "time to check!\n",
      "do we get here?\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "in converted code:\n\n    <ipython-input-12-a7b2ed9308f5>:24 p_loss  *\n        h1_list = model(x)\n    /home/isaiahk/miniconda3/envs/tf2b/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:667 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /home/isaiahk/miniconda3/envs/tf2b/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py:750 call  *\n        raise NotImplementedError('When subclassing the `Model` class, you should'\n\n    NotImplementedError: When subclassing the `Model` class, you should implement a `call` method.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-ea384bb6f893>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_vae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-ad34b49406a6>\u001b[0m in \u001b[0;36mtrain_vae\u001b[0;34m(model, optimizer, epochs, dataset, print_interval, save_interval, log_freq)\u001b[0m\n\u001b[1;32m     49\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'do we get here?'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                     \u001b[0mrc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                     \u001b[0mploss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m                     \u001b[0mavg_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                     \u001b[0mavg_val_rc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrc_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2b/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0minitializer_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2b/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    357\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    358\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 359\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2b/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1360\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1361\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2b/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1646\u001b[0m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1648\u001b[0;31m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1649\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2b/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   1539\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1541\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   1542\u001b[0m         self._function_attributes)\n\u001b[1;32m   1543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2b/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    714\u001b[0m                                           converted_func)\n\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2b/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2b/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    704\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: in converted code:\n\n    <ipython-input-12-a7b2ed9308f5>:24 p_loss  *\n        h1_list = model(x)\n    /home/isaiahk/miniconda3/envs/tf2b/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:667 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /home/isaiahk/miniconda3/envs/tf2b/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py:750 call  *\n        raise NotImplementedError('When subclassing the `Model` class, you should'\n\n    NotImplementedError: When subclassing the `Model` class, you should implement a `call` method.\n"
     ]
    }
   ],
   "source": [
    "train_vae(model, optimizer, 1, train_set, 10, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf2b] *",
   "language": "python",
   "name": "conda-env-tf2b-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
